
import requests
from bs4 import BeautifulSoup
import pandas as pd
import datetime
import csv

def scrape_amazon(search_term, country='US', max_pages=1):
    headers = {
        "User-Agent": "Mozilla/5.0",
    }
    base_url = "https://www.amazon.com" if country == "US" else "https://www.amazon.com.mx"
    products = []

    url = f"{base_url}/s?k={search_term.replace(' ', '+')}"
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    results = soup.find_all("div", {"data-component-type": "s-search-result"})

    for item in results[:10]:
        try:
            title = item.h2.text.strip()
            price = item.find("span", "a-offscreen")
            price = price.text if price else "N/A"
            link = base_url + item.h2.a['href']
            rating = item.find("span", {"class": "a-icon-alt"})
            rating = rating.text if rating else "N/A"

            products.append({
                "Title": title,
                "Price": price,
                "Rating": rating,
                "Link": link,
                "Date": datetime.date.today()
            })
        except Exception:
            continue

    df = pd.DataFrame(products)
    file_path = f"data/amazon_{search_term}_{country}_{datetime.date.today()}.csv"
    df.to_csv(file_path, index=False)
    return df
